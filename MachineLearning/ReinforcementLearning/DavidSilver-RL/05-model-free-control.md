# Model Free Control

å›å¿† Planning ä¸­ Policy Iteration ç®—æ³•
* Policy Evaluationï¼šæ ¹æ®å½“å‰policyé‡‡æ ·ä¸€å †æ•°æ®ï¼Œç„¶åè¿›è¡Œ policy evaluation. (Monte-Carlo, TD ?)
* Policy Improvementï¼šæ ¹æ® policy evaluation ç»“æœ è¿›è¡Œ improve policyã€‚Greedy Policy Improvement?
* ğŸ‘†ä¸Šé¢ä¸¤ä¸ªæ“ä½œä¸åœå¾ªç¯

# Policy Improvement

* Greedy Policy improvement over $V(S)$ requires model of MDP
$$
\pi'(s) = \arg \max_{a \in A} \mathcal R_s^a + \mathcal P_{ss'}^aV(s')
$$

* Greedy policy improvement over $Q(s, a)$ is model-free
$$
\pi'(s) = \arg \max_{a \in A} Q(s, a)
$$
