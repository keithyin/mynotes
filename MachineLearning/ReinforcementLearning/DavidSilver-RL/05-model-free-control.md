# Model Free Control

å›žå¿† Planning ä¸­ Policy Iteration ç®—æ³•
* Policy Evaluationï¼šæ ¹æ®å½“å‰policyé‡‡æ ·ä¸€å †æ•°æ®ï¼Œç„¶åŽè¿›è¡Œ policy evaluation. (Monte-Carlo, TD ?)
* Policy Improvementï¼šæ ¹æ® policy evaluation ç»“æžœ è¿›è¡Œ improve policyã€‚Greedy Policy Improvement?
* ðŸ‘†ä¸Šé¢ä¸¤ä¸ªæ“ä½œä¸åœå¾ªçŽ¯

# Policy Improvement
> policy evaluation å­˜åœ¨ model-based(DP) å’Œ model-free(MC, TD) æ–¹æ³•

* Greedy Policy improvement over $V(S)$ requires model of MDP
$$
\pi'(s) = \arg \max_{a \in A} \mathcal R_s^a + \mathcal P_{ss'}^aV(s')
$$

* Greedy policy improvement over $Q(s, a)$ is model-free
$$
\pi'(s) = \arg \max_{a \in A} Q(s, a)
$$
